---
layout: post
title: FOSDEM 2025 has exceeded my expectations
---
This weekend, I participated in FOSDEM 2025, which impressed me more than I had imagined. Boy, was it big—over 1,000 talks! Here are a few notable takeaways:

### Apache Arrow is a top dog, with a turbulent future
The first panel I attended on day one was Apache Arrow's. It felt surreal to meet the contributors face-to-face—they all seemed like genuinely nice people who simply know their niche very well.

![img](/assets/IMG_2337.jpg)
<center><i>Arrow is the standard in-memory data format for interoperability between languages.</i></center>

<br />

I've been aware of Arrow for a few years, and this panel only reinforced my confidence in it as the standard in-memory data format for interoperability between languages. You can have identically layed-out data in memory in Python, Go, Rust, etc., and pass it around without any serialization or deserialization then. Yes, even with Go, which is a bit of a pain to work with when it comes to Python interop due to a completely different memory layout in both, which means you need to serialize and deserialize data when passing it between the two.

Arrow allows different languages, processes and systems talk with each other at maximum speed... Think English language, but for sofware.

![img](/assets/IMG_2336.jpg)
<center><i>Arrow columnar format is the way more and more engines hold the data in memory, and for a good (interop) reason.</i></center>

<br />

They mentioned a notable application of Arrow at Hugging Face: efficiently handling data larger than memory for LLMs with their Datasets library. We all know how to stream data from disk when RAM is limited - implementing reading in batches - but with Arrow, you can dump memory bytes to disk 1:1 (pure bytes without any changes) and memory-map the disk to "pretend" it's RAM — kind of similar to swapping - but with efficient read-in since no deserialization occurs. So, basically, you dump bytes into a `.arrow` file (with PyArrow), straight into `/tmp/`, and then `mmap`, which is much faster and less code than doing the same with Parquet files. Extremely useful for loading datasets larger than memory in a convenient fashion.

A bit of drama — Voltron Data, the main contributor to Arrow, was hit by layoffs last year. The majority of its staff had to find other jobs, meaning a significant portion of Arrow maintainers left. People expressed their commitment to finding ways to support the Arrow project (e.g., through foundations) to ensure its continued maintenance, but they seemed quite concerned nonetheless.

### Graph databases will not conquer the world, but they have their niches
Great historical talk by one of DuckDB's developer advocates, Gábor Szárnyas, who is apparently a reputable graph database researcher as well! Key takeaway: graph databases excel at nested/recursive multi-join problems because (a) writing SQL for something like the shortest path quickly turns into a mess of LISTAGG, multiple joins, etc., and (b) they leverage factorization under the hood—flattening certain columns into lists to reduce joins (e.g., storing a person's friend list as a list instead of separate rows). This makes them dominant in this niche.

![img](/assets/image-graph.png)
<center><i>Implementing shortest path finding in SQL is no one-liner. A slide from Gábor's talk.</i></center>

<br />
However, graph DBs won't replace RDMS - they are neither faster (usually since they are schemaless), nor better supported (very fragmented landscape due to overfitting to specific use-cases).

On a positive note, his group has made massive leaps on a graph DB benchmarking suite, which should move the field forward either way.

### Opentelemetry + | insert your favorite OLAP engine | is the way to go
There was a talk from a Clickhouse developer advocate, who once more preached Clickhouse for telemetry. He had a point though.

I don't have years of SRE experience to make any strong recommendations here, but having dabbled a bit with the classic Prometheus + Grafana setup, I’ve noticed two issues:

1. PromQL is a terrible language—hard to read and write, especially compared to SQL.
1. Prometheus time-series DB is relatively slow, given the sheer amount of data it has to process.
1. Prometheus instrumentation client is okay, but why lock yourself into Prometheus when you can use OpenTelemetry and switch between different backends?

OK, you may have to set-up some things e.g. a UI, but it's not the hard part i.e. you can set-up Granana with some SQL sources e.g. the Clickhouse, and you're good to go.

From my perspective, it's just that we have ingrained habits of setting up these telemetry stacks. I have to agree with the overly excited ClickHouse presenters: the future telemetry stack is OpenTelemetry (to reduce vendor lock-in) combined with any real-time OLAP database, like ClickHouse. Sums, counts, percentiles, etc., are OLAP’s bread and butter—typically all one- or multi-column operations.

Will benchmark sometime soon. This entire area can be IMHO disrupted™.

### Wasm will not replace containers, but it is the definition of cool
Dan Phillips showcased a pretty cool project he's been developing, which essentially takes a Dockerfile, runs `box build -f Dockerfile`, and produces a WASM binary that can even run in a browser. In general, this results in much lower startup times and better isolation, which I definitely agree with.

Here’s the catch: no, containers are not disappearing. WASM has slower runtime performance because the WASM runtime acts like a VM executing WASM assembly-like bytecode. They are reimplementing every syscall to match the same interface, which requires an astonishing amount of effort. On top of that, they’re reimplementing every Dockerfile command.

Nonetheless, it's a cool project, the author seems like a great enthusiastic engineer, and I can see it being used for short-running FAAS (short runtime, but the syscalls are the real challenge).

### CNCF is a big deal
To be fair, I’d never heard of CNCF, but they’re such a professional non-profit and the parent company of Kubernetes, Prometheus, and many other projects. They shared some thoughts on how they’re not too concerned if some individual contributors disappear for reasons like family commitments, but the bigger issue arises when projects are maintained by a single entity that can just reorganize overnight. Apache Arrow, is that you?

Keep up the good work, CNCF!

### Distributed Systems are (again) notoriously hard to build

![img](/assets/IMG_2339.jpg)
<center><i>Distributed state is hard to get right, and even tiny bugs can lead to catastrophic failures.</i></center>

<br />

"Was Leslie Lamport Right?" — that's the title of the main talk in the distributed systems track. Apparently, the legendary analyst and educator in distributed systems even before he had a distributed system at home. I learned a bit about Lamport clocks and how distributed systems sync in discrete and relative time, not wall-clock time. It made me think that offloading as much state as possible to S3 might not be such a bad idea, and that building one should be (and remain) a highly rewarding side project.

### FSFE is also a big deal
Massive respect for the folks who have been advocating for nearly 20 years for extendable and replaceable software. Although the presenter stirred the pot a bit with the audience—some folks didn’t buy the idea that devices aren't modifiable—but unfortunately, that’s only feasible if you're a 10x hobbyist engineer, not regular folk. Best of luck going forward against Apple (their current target).

The conference beat to dust every commercial conference I have ever been to, an eye-opening experience tech-wise and great for meeting old, existing or new colleagues for some networking. Brussels is the perfect setting for it as well - well connected and just the right European vibes. Great food and drinks too (plenty of food carts and bars)...

Shame I skipped previous 2 FOSDEMs, having been living in Belgium for ~3 years. Overly excited I went this year. Will return next year.